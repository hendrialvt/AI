{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SECTION 1 ---\n",
    "# Libraries and data loading\n",
    "from copy import deepcopy\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "train_size = 400\n",
    "train_x, train_y = diabetes.data[:train_size], diabetes.target[:train_size]\n",
    "test_x, test_y = diabetes.data[train_size:], diabetes.target[train_size:]\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SECTION 2 ---\n",
    "# Create the ensemble\n",
    "\n",
    "# Define the ensemble's size, learning rate and decision tree depth\n",
    "ensemble_size = 50\n",
    "learning_rate = 0.1\n",
    "base_classifier = DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "# Create placeholders for the base learners and each step's prediction\n",
    "base_learners = []\n",
    "# Note that the initial prediction is the target variable's mean\n",
    "previous_predictions = np.zeros(len(train_y)) + np.mean(train_y)\n",
    "\n",
    "# Create the base learners\n",
    "for _ in range(ensemble_size):\n",
    "    # Start by calcualting the pseudo-residuals\n",
    "    errors = train_y - previous_predictions\n",
    "    \n",
    "    # Make a deep copy of the base classifier and train it on the\n",
    "    # pseudo-residuals\n",
    "    learner = deepcopy(base_classifier)\n",
    "    learner.fit(train_x, errors)\n",
    "    \n",
    "    # Predict the residuals on the train set\n",
    "    predictions = learner.predict(train_x)\n",
    "    \n",
    "    # Multiply the predictions with the learning rate and add the results\n",
    "    # to the previous prediction\n",
    "    previous_predictions = previous_predictions + learning_rate*predictions\n",
    "    \n",
    "    # Save the base learner\n",
    "    base_learners.append(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SECTION 3 ---\n",
    "# Evaluate the ensemble\n",
    "\n",
    "# Start with the train set's mean\n",
    "previous_predictions = np.zeros(len(test_y)) + np.mean(train_y)\n",
    "\n",
    "# For each base learner predict the pseudo-residuals for the test set and\n",
    "# add them to the previous prediction, after multiplying with the learning rate\n",
    "for learner in base_learners:\n",
    "    predictions = learner.predict(test_x)\n",
    "    previous_predictions = previous_predictions + learning_rate*predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting:\n",
      "R-squared: 0.59\n",
      "MSE: 2253.34\n"
     ]
    }
   ],
   "source": [
    "# --- SECTION 4 ---\n",
    "# Print the metrics\n",
    "r2 = metrics.r2_score(test_y, previous_predictions)\n",
    "mse = metrics.mean_squared_error(test_y, previous_predictions)\n",
    "\n",
    "print('Gradient Boosting:')\n",
    "print('R-squared: %.2f' % r2)\n",
    "print('MSE: %.2f' % mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
